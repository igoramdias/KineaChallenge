{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import datetime\n",
    "\n",
    "def clear_sheet(sheet: str) -> None:\n",
    "    \"\"\"\n",
    "        Função para limpar a sheet por completo\n",
    "\n",
    "        :param sheet: Nome da string para ser limpada no workbook\n",
    "    \"\"\"\n",
    "\n",
    "    global BDINFRA_path\n",
    "                                                                           \n",
    "    wb = openpyxl.load_workbook(BDINFRA_path)                                       \n",
    "    ws = wb[sheet]\n",
    "\n",
    "    for idx_row, row in enumerate(ws, 1): # Limpando cada célula da sheet\n",
    "        for col in row:\n",
    "            col.value = None\n",
    "    \n",
    "    wb.save(BDINFRA_path) #Salva as alterações\n",
    "\n",
    "def pandas_to_excel(sheet: str, df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "        Realizar a transição de pandas DataFrame para planilha em Excel\n",
    "\n",
    "        :param sheet: Nome da string para ser populada no workbook\n",
    "        :param df: DataFrame para ser usada para popular a sheet\n",
    "    \"\"\"\n",
    "    global BDINFRA_path\n",
    "\n",
    "    wb = openpyxl.load_workbook(BDINFRA_path)                                       \n",
    "    ws = wb[sheet]\n",
    "\n",
    "    rows = dataframe_to_rows(df, index=False) #Transforma o dataframe em várias células\n",
    "\n",
    "    for r_idx, row in enumerate(rows, 1): # Realiza o preenchimento da sheet\n",
    "        for c_idx, value in enumerate(row, 1):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "    wb.save(BDINFRA_path) #Salva as alterações\n",
    "\n",
    "def date_to_file(date: str, type: str) -> str:\n",
    "    \"\"\"\n",
    "        Função para converter a data em nome dos files\n",
    "\n",
    "        :param date: Data a ser analisada\n",
    "        :param type: Para qual documento será feito o ajuste\n",
    "    \"\"\"\n",
    "\n",
    "    dt = date.split('/') # Retira os chars /\n",
    "\n",
    "    # Criação dos nome dos files de acordo com a data o tipo passado\n",
    "    if (type == 'IPCA') or (type == 'CDI') or (type == '%CDI'): \n",
    "        mes = {1: 'jan', 2: 'fev', 3: 'mar', 4: 'abr', 5: 'mai', 6: 'jun', 7: 'jul', 8: 'ago', 9: 'set', 10: 'out', 11: 'nov', 12: 'dez'}\n",
    "        file = 'd'+dt[2][-2:]+mes[int(dt[1])]+dt[0]+'.xls'\n",
    "\n",
    "    if type == 'REUNE':\n",
    "        file = 'REUNE_Acumulada_'+''.join(dt)+'.csv'\n",
    "\n",
    "    if type == 'IMAB':\n",
    "        file = 'IMA_'+''.join(dt)+'.csv'\n",
    "\n",
    "    if type == 'ETTJ':\n",
    "        file = 'CurvaZero_'+''.join(dt)+'.csv'\n",
    "    \n",
    "    return file # Retorna o nome do file\n",
    "\n",
    "def clean(df: pd.DataFrame , type: str) -> Tuple[pd.DataFrame, datetime.datetime]:\n",
    "    \"\"\"\n",
    "        Realizar pré-processamentos para bases a serem exploradas\n",
    "\n",
    "        :param df: DataFrame a ser realizado o pré-processamento\n",
    "        :param type: Para qual documento será feito o pré-processamento\n",
    "    \"\"\"\n",
    "\n",
    "    # Realiza o pré-processamento a depender do tipo\n",
    "    if (type == 'IPCA') or (type == 'CDI') or (type == '%CDI'):\n",
    "        col_1 = list(df.columns)[0]\n",
    "        idx_srt = list(df.index[df[col_1] == 'Código'])[0]\n",
    "        idx_end = list(df.index[df[col_1].astype(str).str.contains(\"[*]\")])[0]\n",
    "        columns = pd.Series(list(df.iloc[idx_srt]))\n",
    "        col_intind = list(columns[columns.astype(str).str.contains('Intervalo Indicativo')])\n",
    "        if len(col_intind) == 1:\n",
    "            columns = columns.fillna('Intervalo Indicativo Máxima')\n",
    "            columns = columns.replace(col_intind[0], \"Intervalo Indicativo Mínimo\")\n",
    "        df.columns = columns\n",
    "        df = df.iloc[idx_srt+2:idx_end]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['Nome'] = [name[:name.index('*')-2] if '*' in name else name for name in df['Nome']]\n",
    "        df['Nome'] = [name[:name.index('#')-2] if '#' in name else name for name in df['Nome']]\n",
    "\n",
    "    if type == 'REUNE':\n",
    "        df = df.reset_index()\n",
    "        col_1 = list(df.columns)[0]\n",
    "        idx_srt = list(df.index[df[col_1].astype(str).str.contains('CETIP')])[0]\n",
    "        columns = pd.Series(list(df.iloc[idx_srt]))\n",
    "        df.columns = columns\n",
    "        df = df.iloc[idx_srt+1:]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df[df['Agrupamento'] != 'SUBTOTAL']\n",
    "        df['Taxa Média'] = df['Taxa Média'].str.replace(',', '.')\n",
    "        df['Preço Médio'] = df['Preço Médio'].str.replace('.', '')\n",
    "        df['Preço Médio'] = df['Preço Médio'].str.replace(',', '.')\n",
    "\n",
    "    if type == 'IMAB':\n",
    "        df = df.reset_index()\n",
    "        col_1 = list(df.columns)[0]\n",
    "        idx_srt = list(df.index[df[col_1].astype(str).str.contains('Data')])[0]\n",
    "        columns = pd.Series(list(df.iloc[idx_srt]))\n",
    "        columns = [col[:col.index('*')] if '*' in col else col for col in columns]\n",
    "        df.columns = columns\n",
    "        df = df.iloc[idx_srt+1:]\n",
    "        df = df.reset_index(drop=True) \n",
    "        df['Duration (d.u.)'] = df['Duration (d.u.)'].str.replace('.', '')\n",
    "        df['Taxa Indicativa (% a.a.)'] = df['Taxa Indicativa (% a.a.)'].str.replace(',', '.')\n",
    "    \n",
    "    if type == 'ETTJ':\n",
    "        col_1 = list(df.columns)[0]\n",
    "        col_2 = list(df.columns)[1]\n",
    "        idx_srt = list(df.index[df[col_1] == 'Vertices'])[0]\n",
    "        idx_end = list(df.index[df[col_2].isnull()])[2]\n",
    "        df.columns = list(df.iloc[idx_srt])\n",
    "        df = df.iloc[idx_srt+1:idx_end]\n",
    "        df = df.drop(list(set(df.columns) - set(['Vertices', 'ETTJ IPCA', 'ETTJ PREF'])), axis = 1)\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['Vertices'] = df['Vertices'].str.replace('.', '')\n",
    "        df['ETTJ IPCA'] = df['ETTJ IPCA'].str.replace(',', '.')\n",
    "        df['ETTJ PREF'] = df['ETTJ PREF'].str.replace(',', '.')\n",
    "    \n",
    "    if type == 'DATA_DEB':\n",
    "        df['Codigo do Ativo'] = df['Codigo do Ativo'].str.replace(' ','')\n",
    "        df.columns = df.columns.str.replace(' ','')\n",
    "    \n",
    "    dt_rat = None\n",
    "    if type == 'RATING':\n",
    "        dt_rat = pd.to_datetime(df.columns[0])\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df.iloc[1:]\n",
    "\n",
    "    return df, dt_rat # Retorna o DataFrame já ajustado para análises\n",
    "\n",
    "downloads_path = \"~\\Downloads\"\n",
    "downloads_path = os.path.expanduser(downloads_path)\n",
    "\n",
    "date = '26/02/2021'\n",
    "\n",
    "global DATA_DEB\n",
    "DATA_DEB = pd.read_table(os.path.join(downloads_path, \"Debentures.com.br_Caracteristica_em_03-03-2021_as_21-19-42.xls\"), encoding='ANSI')\n",
    "DATA_DEB = clean(DATA_DEB, 'DATA_DEB')\n",
    "\n",
    "global IMAB\n",
    "IMAB = pd.read_csv(os.path.join(downloads_path, date_to_file(date, 'IMAB')), sep=\";\", encoding='ANSI')\n",
    "IMAB = clean(IMAB, 'IMAB')\n",
    "\n",
    "global REUNE\n",
    "REUNE = pd.read_csv(os.path.join(downloads_path, date_to_file(date, 'REUNE')),sep=\";\",header=2, encoding='ANSI')\n",
    "REUNE = clean(REUNE, 'REUNE')\n",
    "\n",
    "global TAXAS_IPCA\n",
    "TAXAS_IPCA = pd.read_excel(os.path.join(downloads_path, date_to_file(date, 'IPCA')), sheet_name='IPCA_SPREAD')\n",
    "TAXAS_IPCA = clean(TAXAS_IPCA, 'IPCA')\n",
    "\n",
    "global TAXAS_CDI\n",
    "TAXAS_CDI = pd.read_excel(os.path.join(downloads_path, date_to_file(date, 'CDI')), sheet_name='DI_SPREAD')\n",
    "TAXAS_CDI = clean(TAXAS_CDI, 'CDI')\n",
    "\n",
    "global TAXAS_PCT_CDI\n",
    "TAXAS_PCT_CDI = pd.read_excel(os.path.join(downloads_path, date_to_file(date, '%CDI')), sheet_name='DI_PERCENTUAL')\n",
    "TAXAS_PCT_CDI = clean(TAXAS_PCT_CDI, '%CDI')\n",
    "\n",
    "global ETTJ\n",
    "ETTJ = pd.read_csv(os.path.join(downloads_path, date_to_file(date, 'ETTJ')),sep=\";\", encoding='ANSI')\n",
    "ETTJ = clean(ETTJ, 'ETTJ')\n",
    "\n",
    "global RATING\n",
    "RATING = pd.read_excel(os.path.join(downloads_path, \"Rating.xlsx\"))\n",
    "RATING, dt_rate = clean(RATING, 'RATING')\n",
    "\n",
    "global INCENT\n",
    "INCENT = pd.read_excel(os.path.join(downloads_path, \"003. Debêntures Incentivadas v01.xlsx\"), skiprows=2)\n",
    "\n",
    "global CONVEN\n",
    "CONVEN = pd.read_excel(os.path.join(downloads_path, \"004. Debêntures Convencionais v01.xlsx\"))\n",
    "\n",
    "global BDINFRA_path \n",
    "BDINFRA_path = os.path.join(downloads_path, \"BD Infra - Secundário - Copia.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wis_cadastro() -> None:\n",
    "    \"\"\"\n",
    "        Função para preenchimento das células na planilha Cadastro\n",
    "    \"\"\"\n",
    "    \n",
    "    global REUNE\n",
    "    global TAXAS_IPCA\n",
    "    global TAXAS_DI\n",
    "    global INCENT\n",
    "    global CONVEN\n",
    "    global BDINFRA_path\n",
    "\n",
    "    sheet = 'Cadastro' # Selecionando a sheet a ser manipulada\n",
    "\n",
    "    df = pd.read_excel(BDINFRA_path, sheet_name=sheet)\n",
    "    df = df[df['Ticker'].notna()] # Retira possíveis vazios\n",
    "    \n",
    "    aux = pd.DataFrame(columns=df.columns)\n",
    "    for idx_row, row in DATA_DEB.iterrows():\n",
    "        # Checa se o ticker não está presente na sheet\n",
    "        if not (row['CodigodoAtivo'] in list(df['Ticker'])):\n",
    "            # Determina se o ticker pertecente à infraestrutura ou não\n",
    "            infra = 0\n",
    "            ## Note que em INCEN só tem IPCA e em CONVEN só tem CDI, não levar nenhum %CDI\n",
    "            if (row['CodigodoAtivo'] in list(INCENT['Ativo'])) or (row['CodigodoAtivo'] in list(CONVEN['Ativo'])):\n",
    "                infra = 1\n",
    "            # Preenchimento das colunas\n",
    "            aux = aux.append({\n",
    "                'Ticker': row['CodigodoAtivo'], \n",
    "                'Emissor': row['Empresa'], \n",
    "                'Infraestrutura': infra, \n",
    "                'Data de Saida/Nova Data de Vencimento': row['DatadeSaida/NovoVencimento'],\n",
    "                'Garantia/Especie': row['Garantia/Especie'], \n",
    "                'Valor Nominal na Emissão': row['ValorNominalnaEmissao'],\n",
    "                'Índice': row['indice'], \n",
    "                'Percentual Multiplicador/Rentabilidade': row['PercentualMultiplicador/Rentabilidade'],\n",
    "                'CNPJ': row['CNPJ'],\n",
    "                'Deb. Incentivada (Lei12.431)': row['Deb.Incent.(Lei12.431)'],\n",
    "                'Resgate Antecipado': row['ResgateAntecipado']}, ignore_index=True)\n",
    "\n",
    "    df = df.append(aux, ignore_index=True) # Junta os dados novos com os antigos\n",
    "\n",
    "    clear_sheet(sheet) # Limpa a sheet com os dados antigos\n",
    "    pandas_to_excel(sheet, df) # Preenche a sheet com os dados antigos e novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wis_cadastro_infra() -> None:\n",
    "    \"\"\"\n",
    "        Função para preenchimento das células na planilha Cadastro Infra\n",
    "    \"\"\"\n",
    "    \n",
    "    global REUNE\n",
    "    global TAXAS_IPCA\n",
    "    global TAXAS_DI\n",
    "    global INCENT\n",
    "    global CONVEN\n",
    "    global BDINFRA_path\n",
    "\n",
    "    sheet = 'Cadastro Infra' # Selecionando a sheet a ser manipulada\n",
    "\n",
    "    df_cad = pd.read_excel(BDINFRA_path, sheet_name='Cadastro')\n",
    "    df_cad = df_cad[df_cad['Infraestrutura'] == 1] # Seleciona as rows somente das que forem de infra\n",
    "\n",
    "    df = pd.read_excel(BDINFRA_path, sheet_name=sheet)\n",
    "    df = df[df['Ticker'].notna()] # Retira possíveis vazios\n",
    "\n",
    "    aux = pd.DataFrame(columns=df.columns)\n",
    "    for idx_row, row in df_cad.iterrows():\n",
    "        # Checa se o ticker não está presente na sheet\n",
    "        if not (row['Ticker'] in list(df['Ticker'])):\n",
    "\n",
    "            indexador = np.nan\n",
    "            incentivada = np.nan\n",
    "            emissor = np.nan\n",
    "            setor = np.nan\n",
    "            subsetor = np.nan\n",
    "            ag_rat = np.nan\n",
    "            rat_emi = np.nan\n",
    "            # Checa se o ticker está na planilha TAXAS_IPCA\n",
    "            if row['Ticker'] in list(TAXAS_IPCA['Código']):\n",
    "                indexador = 'IPCA'\n",
    "                incentivada = 1\n",
    "                emissor = TAXAS_IPCA[TAXAS_IPCA['Código'] == row['Ticker']]['Nome'].iloc[0]\n",
    "            # Checa se o ticker está na planilha TAXAS_CDI\n",
    "            elif row['Ticker'] in list(TAXAS_CDI['Código']): \n",
    "                indexador = 'CDI'\n",
    "                incentivada = 0\n",
    "                emissor = TAXAS_CDI[TAXAS_CDI['Código'] == row['Ticker']]['Nome'].iloc[0]\n",
    "            # Checa se o ticker está na planilha TAXAS_PCT_CDI\n",
    "            elif (row['Ticker'] in list(TAXAS_PCT_CDI['Código'])): \n",
    "                indexador = '%CDI'\n",
    "                incentivada = 0\n",
    "                emissor = TAXAS_PCT_CDI[TAXAS_PCT_CDI['Código'] == row['Ticker']]['Nome'].iloc[0]\n",
    "            # Checa se o ticker está na planilha INCENTIVADA\n",
    "            ##Tira essas infos do INCENT e CONVEN ou do DATA_DEB ? Melhor ser no DATA_DEB\n",
    "            elif row['Ticker'] in list(INCENT['Ativo']):\n",
    "                indexador = 'IPCA'\n",
    "                incentivada = 1\n",
    "                emissor = INCENT[INCENT['Ativo'] == row['Ticker']]['Titular'].iloc[0]\n",
    "                setor = INCENT[INCENT['Ativo'] == row['Ticker']]['Setor'].iloc[0]\n",
    "                subsetor = INCENT[INCENT['Ativo'] == row['Ticker']]['Subsetor'].iloc[0]\n",
    "                ag_rat = INCENT[INCENT['Ativo'] == row['Ticker']]['Agência (Emissão, Br)'].iloc[0]\n",
    "                rat_emi = INCENT[INCENT['Ativo'] == row['Ticker']]['Rating (Emissão, Br)'].iloc[0]\n",
    "            # Checa se o ticker está na planilha CONVENCIONAL\n",
    "            elif row['Ticker'] in list(CONVEN['Ativo']): ##Assumindo que CONVEN é só CDI\n",
    "                indexador = 'CDI'\n",
    "                incentivada = 0\n",
    "                emissor = CONVEN[CONVEN['Ativo'] == row['Ticker']]['Titular'].iloc[0]\n",
    "                setor = CONVEN[CONVEN['Ativo'] == row['Ticker']]['Setor'].iloc[0]\n",
    "                subsetor = CONVEN[CONVEN['Ativo'] == row['Ticker']]['Subsetor'].iloc[0]\n",
    "                ag_rat = CONVEN[CONVEN['Ativo'] == row['Ticker']]['Agência (Emissão, Br)'].iloc[0]\n",
    "                rat_emi = CONVEN[CONVEN['Ativo'] == row['Ticker']]['Rating (Emissão, Br)'].iloc[0]\n",
    "            # Chega para não colocar uma row vazia\n",
    "            if (indexador != np.nan):\n",
    "                # Preenchimento das colunas\n",
    "                aux = aux.append({\n",
    "                    'Ticker': row['Ticker'],\n",
    "                    'Indexador': indexador, \n",
    "                    'Incentivada': incentivada,\n",
    "                    'Emissor': emissor,\n",
    "                    'Setor': setor,\n",
    "                    'Subsetor': subsetor,\n",
    "                    'Flag Consolidado': np.nan,\n",
    "                    'Flag Resumo': np.nan,\n",
    "                    'Agência rating': ag_rat,\n",
    "                    'Rating de emissão': rat_emi}, ignore_index=True)\n",
    "\n",
    "    df = df.append(aux, ignore_index=True) # Junta os dados novos com os antigos\n",
    "\n",
    "    clear_sheet(sheet) # Limpa a sheet com os dados antigos\n",
    "    pandas_to_excel(sheet, df) # Preenche a sheet com os dados antigos e novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wis_rating() -> None:\n",
    "    \"\"\"\n",
    "        Função para preenchimento das células na planilha Rating\n",
    "    \"\"\"\n",
    "\n",
    "    global RATING\n",
    "    global BDINFRA_path\n",
    "    global date\n",
    "\n",
    "    sheet = 'Rating' # Selecionando a sheet a ser manipulada\n",
    "\n",
    "\n",
    "    df_cad_infra = pd.read_excel(BDINFRA_path, sheet_name='Cadastro Infra')\n",
    "    df_cad_infra = df_cad_infra.iloc[1:] # Retira as explicações de cada célula\n",
    "\n",
    "    df = pd.read_excel(BDINFRA_path, sheet_name=sheet)\n",
    "    df = df[df['Ticker'].notna()] # Retira possíveis vazios\n",
    "\n",
    "    aux = pd.DataFrame(columns=df.columns)\n",
    "    for idx_row, row in df_cad_infra.iterrows():\n",
    "        # Checa se o ticker não está presente na sheet ou se, estando, está sendo uma data diferente para popular\n",
    "        if (not (row['Ticker'] in list(df['Ticker']))) or (not (date in list(df[df['Ticker'] == row['Ticker']]['Dia']))):\n",
    "            \n",
    "            ag_ret = np.nan\n",
    "            rat = np.nan\n",
    "            rat_eq = np.nan\n",
    "            # Checa se o ticker está nas planilha RATING\n",
    "            if row['Ticker'] in list(RATING['Emissor']):\n",
    "                ag_ret = RATING[RATING['Emissor'] == row['Ticker']]['Agência'].iloc[0]\n",
    "                rat = RATING[RATING['Emissor'] == row['Ticker']]['Rating'].iloc[0]\n",
    "                rat_eq = RATING[RATING['Emissor'] == row['Ticker']]['Rating Equivalente'].iloc[0]\n",
    "            # Preenchimento das colunas\n",
    "            aux = aux.append({\n",
    "                'Dia': date,\n",
    "                'Ticker': row['Ticker'], \n",
    "                'Agência de Rating': ag_ret,\n",
    "                'Rating': rat,\n",
    "                'Rating Equivalente': rat_eq}, ignore_index=True)\n",
    "\n",
    "\t\t\t\t\n",
    "    df = df.append(aux, ignore_index=True) # Junta os dados novos com os antigos\n",
    "\n",
    "    clear_sheet(sheet) # Limpa a sheet com os dados antigos\n",
    "    pandas_to_excel(sheet, df) # Preenche a sheet com os dados antigos e novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wis_ipca_anbima() -> None:\n",
    "    \"\"\"\n",
    "        Função para preenchimento das células na planilha IPCA - ANBIMA\n",
    "    \"\"\"\n",
    "\n",
    "    global TAXAS_IPCA\n",
    "    global BDINFRA_path\n",
    "    global IMAB\n",
    "    global ETTJ\n",
    "    global date\n",
    "\n",
    "    sheet = 'IPCA - ANBIMA' # Selecionando a sheet a ser manipulada\n",
    "\n",
    "    df_cad_infra = pd.read_excel(BDINFRA_path, sheet_name='Cadastro Infra')\n",
    "    df_cad_infra = df_cad_infra[df_cad_infra['Indexador'] == 'IPCA'] # Seleciona as rows somente das que forem com o indexador em IPCA\n",
    "\n",
    "    df = pd.read_excel(BDINFRA_path, sheet_name=sheet)\n",
    "    df = df[df['Ticker'].notna()] # Retira possíveis vazios\n",
    "\n",
    "    aux = pd.DataFrame(columns=df.columns)\n",
    "    for idx_row, row in df_cad_infra.iterrows(): \n",
    "        # Checa se o ticker não está presente na sheet ou se, estando, está sendo uma data diferente para popular\n",
    "        if (not (row['Ticker'] in list(df['Ticker']))) or (not (date in list(df[df['Ticker'] == row['Ticker']]['Dia']))):\n",
    "            \n",
    "            ticker = np.nan\n",
    "            pu_anbima = np.nan\n",
    "            durat_anbima = np.nan\n",
    "            taxa_anbima = np.nan\n",
    "            ntnb_ref_anbima_date = np.nan\n",
    "            ntnb_ref_anbima_tax = np.nan\n",
    "            spread_anbima_ntnb = np.nan\n",
    "            ettj_ref_anbima_tax = np.nan\n",
    "            spread_anbima_ettj = np.nan \n",
    "            # Checa se o ticker está nas planilha TAXAS_IPCA\n",
    "            if row['Ticker'] in list(TAXAS_IPCA['Código']):\n",
    "                ticker = row['Ticker']\n",
    "                pu_anbima = TAXAS_IPCA[TAXAS_IPCA['Código'] == row['Ticker']]['PU'].iloc[0] \n",
    "                taxa_anbima = TAXAS_IPCA[TAXAS_IPCA['Código'] == row['Ticker']]['Taxa Indicativa'].iloc[0]\n",
    "                durat_anbima = TAXAS_IPCA[TAXAS_IPCA['Código'] == row['Ticker']]['Duration'].iloc[0] \n",
    "                durat_anbima = int(durat_anbima) if durat_anbima != 'N/D' else np.nan\n",
    "                # Caso tenha um valor para duration\n",
    "                if durat_anbima != np.nan:  \n",
    "                    # Cálculo do valor mais prócimo de duration disponível\n",
    "                    durat_ref_ntnb = np.array(IMAB['Duration (d.u.)'])[(np.abs(np.array(IMAB['Duration (d.u.)']).astype(int) - durat_anbima)).argmin()] \n",
    "                    # Filta a data de vencimento correspondente\n",
    "                    ntnb_ref_anbima_date = IMAB[IMAB['Duration (d.u.)'] == durat_ref_ntnb]['Data  de Vencimento'].iloc[0]\n",
    "                    # Filta a taxa indicativa correspondente\n",
    "                    ntnb_ref_anbima_tax = float(IMAB[IMAB['Duration (d.u.)'] == durat_ref_ntnb]['Taxa Indicativa (% a.a.)'].iloc[0])\n",
    "                    # Cálculo do spread entre anbima e ntnb\n",
    "                    spread_anbima_ntnb = (1+taxa_anbima)/(1+ntnb_ref_anbima_tax) - 1\n",
    "                    # Interpolação entre os durations de ettj e suas taxas ettj ipca e o duration usado\n",
    "                    ettj_ref_anbima_tax = np.interp(durat_anbima, np.array(ETTJ['Vertices']).astype(int), np.array(ETTJ['ETTJ IPCA']).astype(float))\n",
    "                    # Cálculo do spread entre anbima e ettj\n",
    "                    spread_anbima_ettj = (1+taxa_anbima)/(1+ettj_ref_anbima_tax) - 1\n",
    "                # Preenchimento das colunas\n",
    "                aux = aux.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Dia': date, \n",
    "                    'PU ANBIMA': pu_anbima,\n",
    "                    'Duration ANBIMA': durat_anbima,\n",
    "                    'Taxa ANBIMA': taxa_anbima,\n",
    "                    'NTN-B Ref ANBIMA': ntnb_ref_anbima_date,\n",
    "                    'Taxa NTN-B Ref ANBIMA': ntnb_ref_anbima_tax,\n",
    "                    'Spread B Ref ANBIMA': spread_anbima_ntnb,\n",
    "                    'Taxa ETTJ Ref ANBIMA': ettj_ref_anbima_tax,\n",
    "                    'Spread ETTJ Ref ANBIMA': spread_anbima_ettj}, ignore_index=True)\n",
    "\n",
    "    df = df.append(aux, ignore_index=True) # Junta os dados novos com os antigos\n",
    "\n",
    "    clear_sheet(sheet) # Limpa a sheet com os dados antigos\n",
    "    pandas_to_excel(sheet, df) # Preenche a sheet com os dados antigos e novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wis_ipca_mercado() -> None:\n",
    "    \"\"\"\n",
    "        Função para preenchimento das células na planilha IPCA - Mercado\n",
    "    \"\"\"\n",
    "\n",
    "    global REUNE\n",
    "    global IMAB\n",
    "    global ETTJ\n",
    "    global BDINFRA_path\n",
    "    global date\n",
    "\n",
    "    sheet = 'IPCA - Mercado' # Selecionando a sheet a ser manipulada\n",
    "\n",
    "    df_cad_infra = pd.read_excel(BDINFRA_path, sheet_name='Cadastro Infra')\n",
    "    df_cad_infra = df_cad_infra[df_cad_infra['Indexador'] == 'IPCA'] # Seleciona as rows somente das que forem com o indexador em IPCA\n",
    "\n",
    "    df = pd.read_excel(BDINFRA_path, sheet_name=sheet)\n",
    "    df = df[df['Ticker'].notna()] # Retira possíveis vazios\n",
    "\n",
    "    aux = pd.DataFrame(columns=df.columns)\n",
    "    for idx_row, row in df_cad_infra.iterrows():\n",
    "        # Checa se o ticker não está presente na sheet ou se, estando, está sendo uma data diferente para popular \n",
    "        if (not (row['Ticker'] in list(df['Ticker']))) or (not (date in list(df[df['Ticker'] == row['Ticker']]['Dia']))):\n",
    "            \n",
    "            ticker = np.nan\n",
    "            vol_neg = np.nan\n",
    "            pu_mercado = np.nan\n",
    "            durat_mercado = np.nan\n",
    "            taxa_mercado = np.nan\n",
    "            ntnb_ref_mercado_date = np.nan\n",
    "            ntnb_ref_mercado_tax = np.nan\n",
    "            spread_mercado_ntnb = np.nan\n",
    "            ettj_ref_mercado_tax = np.nan\n",
    "            spread_mercado_ettj = np.nan \n",
    "            # Checa se o ticker está nas planilha REUNE\n",
    "            if row['Ticker'] in list(REUNE['CETIP']):\n",
    "                ticker = row['Ticker']\n",
    "                vol_neg =  REUNE[REUNE['CETIP'] == row['Ticker']]['Faixa de Volume'].iloc[0]\n",
    "                pu_mercado = float(REUNE[REUNE['CETIP'] == row['Ticker']]['Preço Médio'].iloc[0])\n",
    "                taxa_mercado = REUNE[REUNE['CETIP'] == row['Ticker']]['Taxa Média'].iloc[0]\n",
    "                taxa_mercado = float(taxa_mercado) if taxa_mercado != '--' else np.nan\n",
    "                # Por enquanto, utilizando o duration da ANBIMA\n",
    "                durat_mercado = TAXAS_IPCA[TAXAS_IPCA['Código'] == row['Ticker']]['Duration'].iloc[0] if row['Ticker'] in list(TAXAS_IPCA['Código']) else 'N/D'\n",
    "                durat_mercado = int(durat_mercado) if durat_mercado != 'N/D' else np.nan \n",
    "                # Caso tenha um valor para duration e de taxa indicativa\n",
    "                if (durat_mercado != np.nan) and (taxa_mercado != np.nan):\n",
    "                    # Cálculo do valor mais prócimo de duration disponível\n",
    "                    durat_ref_ntnb = np.array(IMAB['Duration (d.u.)'])[(np.abs(np.array(IMAB['Duration (d.u.)']).astype(int) - durat_mercado)).argmin()]\n",
    "                    # Filta a data de vencimento correspondente\n",
    "                    ntnb_ref_mercado_date = IMAB[IMAB['Duration (d.u.)'] == durat_ref_ntnb]['Data  de Vencimento'].iloc[0]\n",
    "                    # Filta a taxa indicativa correspondente\n",
    "                    ntnb_ref_mercado_tax = float(IMAB[IMAB['Duration (d.u.)'] == durat_ref_ntnb]['Taxa Indicativa (% a.a.)'].iloc[0])\n",
    "                    # Cálculo do spread entre mercado e ntnb\n",
    "                    spread_mercado_ntnb = (1+taxa_mercado)/(1+ntnb_ref_mercado_tax) - 1\n",
    "                    # Interpolação entre os durations de ettj e suas taxas ettj ipca e o duration usado\n",
    "                    ettj_ref_mercado_tax = np.interp(durat_mercado, np.array(ETTJ['Vertices']).astype(int), np.array(ETTJ['ETTJ IPCA']).astype(float))\n",
    "                    # Cálculo do spread entre mercado e ettj\n",
    "                    spread_mercado_ettj = (1+taxa_mercado)/(1+ettj_ref_mercado_tax) - 1\n",
    "                # Preenchimento das colunas\n",
    "                aux = aux.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Dia': date, \n",
    "                    'Volume Negociado': vol_neg,\n",
    "                    'PU Mercado': pu_mercado,\n",
    "                    'Duration Mercado': durat_mercado,\n",
    "                    'Taxa Mercado': taxa_mercado,\n",
    "                    'NTN-B Ref Mercado': ntnb_ref_mercado_date,\n",
    "                    'Taxa NTN-B Ref Mercado': ntnb_ref_mercado_tax,\n",
    "                    'Spread B Ref Mercado': spread_mercado_ntnb,\n",
    "                    'Taxa ETTJ Ref Mercado': ettj_ref_mercado_tax,\n",
    "                    'Spread ETTJ Ref Mercado ': spread_mercado_ettj}, ignore_index=True)\n",
    "\n",
    "    df = df.append(aux, ignore_index=True) # Junta os dados novos com os antigos\n",
    "\n",
    "    clear_sheet(sheet) # Limpa a sheet com os dados antigos\n",
    "    pandas_to_excel(sheet, df) # Preenche a sheet com os dados antigos e novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wis_cdi_anbima() -> None:\n",
    "    \"\"\"\n",
    "        Função para preenchimento das células na planilha CDI - ANBIMA\n",
    "    \"\"\"\n",
    "\n",
    "    global TAXAS_CDI\n",
    "    global BDINFRA_path\n",
    "    global date\n",
    "\n",
    "    sheet = 'CDI - ANBIMA' # Selecionando a sheet a ser manipulada\n",
    "\n",
    "    df_cad_infra = pd.read_excel(BDINFRA_path, sheet_name='Cadastro Infra')\n",
    "    df_cad_infra = df_cad_infra[df_cad_infra['Indexador'] == 'CDI'] # Seleciona as rows somente das que forem com o indexador em CDI\n",
    "\n",
    "    df = pd.read_excel(BDINFRA_path, sheet_name=sheet)\n",
    "    df = df[df['Ticker'].notna()] # Retira possíveis vazios\n",
    "\n",
    "    aux = pd.DataFrame(columns=df.columns)\n",
    "    for idx_row, row in df_cad_infra.iterrows(): \n",
    "        # Checa se o ticker não está presente na sheet ou se, estando, está sendo uma data diferente para popular\n",
    "        if (not (row['Ticker'] in list(df['Ticker']))) or (not (date in list(df[df['Ticker'] == row['Ticker']]['Dia']))):\n",
    "\n",
    "            ticker = np.nan\n",
    "            pu_anbima = np.nan\n",
    "            durat_anbima = np.nan\n",
    "            taxa_anbima = np.nan\n",
    "            spread_anbima = np.nan\n",
    "            # Checa se o ticker está nas planilha TAXAS_CDI\n",
    "            if row['Ticker'] in list(TAXAS_CDI['Código']):\n",
    "                ticker = row['Ticker']\n",
    "                pu_anbima = TAXAS_CDI[TAXAS_CDI['Código'] == row['Ticker']]['PU'].iloc[0]\n",
    "                durat_anbima = TAXAS_CDI[TAXAS_CDI['Código'] == row['Ticker']]['Duration'].iloc[0]\n",
    "                durat_anbima = int(durat_anbima) if durat_anbima != 'N/D' else np.nan\n",
    "                taxa_anbima = TAXAS_CDI[TAXAS_CDI['Código'] == row['Ticker']]['Taxa Indicativa'].iloc[0]\n",
    "                spread_anbima = taxa_anbima\n",
    "                # Preenchimento das colunas\n",
    "                aux = aux.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Dia': date, \n",
    "                    'PU ANBIMA': pu_anbima,\n",
    "                    'Duration ANBIMA': durat_anbima,\n",
    "                    'Taxa ANBIMA': taxa_anbima,\n",
    "                    'Spread ANBIMA': spread_anbima}, ignore_index=True)\n",
    "\n",
    "    df = df.append(aux, ignore_index=True) # Junta os dados novos com os antigos\n",
    "\n",
    "    clear_sheet(sheet) # Limpa a sheet com os dados antigos\n",
    "    pandas_to_excel(sheet, df) # Preenche a sheet com os dados antigos e novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wis_cdi_mercado() -> None:\n",
    "    \"\"\"\n",
    "        Função para preenchimento das células na planilha CDI - Mercado\n",
    "    \"\"\"\n",
    "\n",
    "    global REUNE\n",
    "    global IMAB\n",
    "    global BDINFRA_path\n",
    "    global date\n",
    "\n",
    "    sheet = 'CDI - Mercado' # Selecionando a sheet a ser manipulada\n",
    "\n",
    "    df_cad_infra = pd.read_excel(BDINFRA_path, sheet_name='Cadastro Infra')\n",
    "    df_cad_infra = df_cad_infra[df_cad_infra['Indexador'] == 'CDI'] # Seleciona as rows somente das que forem com o indexador em CDI\n",
    "\n",
    "    df = pd.read_excel(BDINFRA_path, sheet_name=sheet)\n",
    "    df = df[df['Ticker'].notna()] # Retira possíveis vazios\n",
    "\n",
    "    aux = pd.DataFrame(columns=df.columns)\n",
    "    for idx_row, row in df_cad_infra.iterrows(): \n",
    "        # Checa se o ticker não está presente na sheet ou se, estando, está sendo uma data diferente para popular\n",
    "        if (not (row['Ticker'] in list(df['Ticker']))) or (not (date in list(df[df['Ticker'] == row['Ticker']]['Dia']))):\n",
    "\n",
    "            ticker = np.nan\n",
    "            vol_neg = np.nan\n",
    "            pu_mercado = np.nan\n",
    "            durat_mercado = np.nan\n",
    "            taxa_mercado = np.nan\n",
    "            spread_mercado = np.nan\n",
    "            # Checa se o ticker está nas planilha REUNE\n",
    "            if row['Ticker'] in list(REUNE['CETIP']):\n",
    "                ticker = row['Ticker']\n",
    "                vol_neg = REUNE[REUNE['CETIP'] == row['Ticker']]['Faixa de Volume'].iloc[0]\n",
    "                pu_mercado = float(REUNE[REUNE['CETIP'] == row['Ticker']]['Preço Médio'].iloc[0])\n",
    "                taxa_mercado = REUNE[REUNE['CETIP'] == row['Ticker']]['Taxa Média'].iloc[0]\n",
    "                taxa_mercado = float(taxa_mercado) if taxa_mercado != '--' else np.nan\n",
    "                spread_mercado = taxa_mercado\n",
    "                # Caso tenha um valor de taxa indicativa\n",
    "                if (taxa_mercado != np.nan):\n",
    "                    # Interpolação entre as taxas de ntnb e os durations e a taxa usada\n",
    "                    durat_mercado = np.interp(taxa_mercado, np.array(IMAB['Taxa Indicativa (% a.a.)']).astype(float), np.array(IMAB['Duration (d.u.)']).astype(int))\n",
    "                # Preenchimento das colunas\n",
    "                aux = aux.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Dia': date, \n",
    "                    'Volume Negociado': vol_neg,\n",
    "                    'PU Mercado': pu_mercado,\n",
    "                    'Duration Mercado': durat_mercado,\n",
    "                    'Taxa Mercado': taxa_mercado,\n",
    "                    'Spread Mercado': spread_mercado}, ignore_index=True)\n",
    "\n",
    "    df = df.append(aux, ignore_index=True) # Junta os dados novos com os antigos\n",
    "\n",
    "    clear_sheet(sheet) # Limpa a sheet com os dados antigos\n",
    "    pandas_to_excel(sheet, df) # Preenche a sheet com os dados antigos e novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wis_pct_cdi_anbima() -> None: \n",
    "    \"\"\"\n",
    "        Função para preenchimento das células na planilha %CDI - ANBIMA\n",
    "    \"\"\"\n",
    "\n",
    "    global TAXAS_PCT_CDI\n",
    "    global BDINFRA_path\n",
    "    global date\n",
    "\n",
    "    sheet = '%CDI - ANBIMA' # Selecionando a sheet a ser manipulada\n",
    "\n",
    "    df_cad_infra = pd.read_excel(BDINFRA_path, sheet_name='Cadastro Infra')\n",
    "    df_cad_infra = df_cad_infra[df_cad_infra['Indexador'] == '%CDI'] # Seleciona as rows somente das que forem com o indexador em %CDI\n",
    "\n",
    "    df = pd.read_excel(BDINFRA_path, sheet_name=sheet)\n",
    "    df = df[df['Ticker'].notna()] # Retira possíveis vazios\n",
    "\n",
    "    aux = pd.DataFrame(columns=df.columns)\n",
    "    for idx_row, row in df_cad_infra.iterrows(): \n",
    "        # Checa se o ticker não está presente na sheet ou se, estando, está sendo uma data diferente para popular\n",
    "        if (not (row['Ticker'] in list(df['Ticker']))) or (not (date in list(df[df['Ticker'] == row['Ticker']]['Dia']))):\n",
    "\n",
    "            ticker = np.nan\n",
    "            taxa_emi = np.nan\n",
    "            pu_anbima = np.nan\n",
    "            durat_anbima = np.nan\n",
    "            taxa_anbima = np.nan\n",
    "            pre_ref_anbima_date = np.nan\n",
    "            pre_ref_anbima_tax = np.nan\n",
    "            spread_anbima_pre = np.nan\n",
    "            ettj_ref_anbima_tax = np.nan\n",
    "            spread_anbima_ettj = np.nan\n",
    "            # Checa se o ticker está nas planilha TAXAS_PCT_CDI\n",
    "            if row['Ticker'] in list(TAXAS_PCT_CDI['Código']):\n",
    "                ticker = row['Ticker']\n",
    "                taxa_emi = TAXAS_PCT_CDI[TAXAS_PCT_CDI['Código'] == row['Ticker']]['Nome'].iloc[0]\n",
    "                pu_anbima = TAXAS_PCT_CDI[TAXAS_PCT_CDI['Código'] == row['Ticker']]['PU'].iloc[0]\n",
    "                durat_anbima = TAXAS_PCT_CDI[TAXAS_PCT_CDI['Código'] == row['Ticker']]['Duration'].iloc[0]\n",
    "                durat_anbima = int(durat_anbima) if durat_anbima != 'N/D' else np.nan\n",
    "                taxa_anbima = TAXAS_PCT_CDI[TAXAS_PCT_CDI['Código'] == row['Ticker']]['Taxa Indicativa'].iloc[0]\n",
    "                # Caso tenha um valor de duration\n",
    "                if durat_anbima != np.nan:\n",
    "                    # Valores nulos por enquanto\n",
    "                    pre_ref_anbima_date = np.nan\n",
    "                    pre_ref_anbima_tax = np.nan\n",
    "                    spread_anbima_pre = np.nan\n",
    "                    # Interpolação entre os durations de ettj e seus taxas ettj pref e o duration usado\n",
    "                    ettj_ref_anbima_tax = np.interp(durat_mercado, np.array(ETTJ['Vertices']).astype(int), np.array(ETTJ['ETTJ PREF']).astype(float))\n",
    "                    # Cálculo do spread entre anbima e ettj\n",
    "                    spread_anbima_ettj = (1+taxa_anbima)/(1+ettj_ref_anbima_tax) - 1\n",
    "                # Preenchimento das colunas\n",
    "                aux = aux.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Dia': date, \n",
    "                    'Taxa Emissão': taxa_emi,\n",
    "                    'PU ANBIMA': pu_anbima,\n",
    "                    'Duration ANBIMA': durat_anbima,\n",
    "                    'Taxa ANBIMA': taxa_anbima,\n",
    "                    'Pré Ref ANBIMA': pre_ref_anbima_date,\n",
    "                    'Taxa Pré Ref ANBIMA': pre_ref_anbima_tax,\n",
    "                    'Spread Pré Ref ANBIMA': spread_anbima_pre,\n",
    "                    'Taxa ETTJ Ref ANBIMA': ettj_ref_anbima_tax,\n",
    "                    'Spread ETTJ Ref ANBIMA': spread_anbima_ettj}, ignore_index=True)\n",
    "\n",
    "    df = df.append(aux, ignore_index=True) # Junta os dados novos com os antigos\n",
    "\n",
    "    clear_sheet(sheet) # Limpa a sheet com os dados antigos\n",
    "    pandas_to_excel(sheet, df) # Preenche a sheet com os dados antigos e novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wis_pct_cdi_mercado() -> None:\n",
    "    \"\"\"\n",
    "        Função para preenchimento das células na planilha %CDI - Mercado\n",
    "    \"\"\"\n",
    "\n",
    "    global REUNE\n",
    "    global BDINFRA_path\n",
    "    global date\n",
    "\n",
    "    sheet = '%CDI - Mercado' # Selecionando a sheet a ser manipulada\n",
    "\n",
    "    df_cad_infra = pd.read_excel(BDINFRA_path, sheet_name='Cadastro Infra')\n",
    "    df_cad_infra = df_cad_infra[df_cad_infra['Indexador'] == '%CDI'] # Seleciona as rows somente das que forem com o indexador em %CDI\n",
    "\n",
    "    df = pd.read_excel(BDINFRA_path, sheet_name=sheet)\n",
    "    df = df[df['Ticker'].notna()] # Retira possíveis vazios\n",
    "\n",
    "    aux = pd.DataFrame(columns=df.columns)\n",
    "    for idx_row, row in df_cad_infra.iterrows(): \n",
    "        # Checa se o ticker não está presente na sheet ou se, estando, está sendo uma data diferente para popular\n",
    "        if (not (row['Ticker'] in list(df['Ticker']))) or (not (date in list(df[df['Ticker'] == row['Ticker']]['Dia']))):\n",
    "\n",
    "            ticker = np.nan\n",
    "            taxa_emi = np.nan\n",
    "            vol_neg = np.nan\n",
    "            pu_mercado = np.nan\n",
    "            durat_mercado = np.nan\n",
    "            taxa_mercado = np.nan\n",
    "            pre_ref_mercado_date = np.nan\n",
    "            pre_ref_mercado_tax = np.nan\n",
    "            spread_mercado_pre = np.nan\n",
    "            ettj_ref_mercado_tax = np.nan\n",
    "            spread_mercado_ettj = np.nan\n",
    "            # Checa se o ticker está nas planilha REUNE\n",
    "            if row['Ticker'] in list(REUNE['CETIP']):\n",
    "                ticker = row['Ticker']\n",
    "                taxa_emi = TAXAS_PCT_CDI[TAXAS_PCT_CDI['Código'] == row['Ticker']]['Nome'].iloc[0] if row['Ticker'] in list(TAXAS_PCT_CDI['Código']) else np.nan\n",
    "                vol_neg = REUNE[REUNE['CETIP'] == row['Ticker']]['Faixa de Volume'].iloc[0]\n",
    "                pu_mercado = float(REUNE[REUNE['CETIP'] == row['Ticker']]['Preço Médio'].iloc[0])\n",
    "                durat_mercado = TAXAS_PCT_CDI[TAXAS_PCT_CDI['Código'] == row['Ticker']]['Duration'].iloc[0] if row['Ticker'] in list(TAXAS_PCT_CDI['Código']) else 'N/D'\n",
    "                durat_mercado = int(durat_mercado) if durat_mercado != 'N/D' else np.nan \n",
    "                taxa_mercado = REUNE[REUNE['CETIP'] == row['Ticker']]['Taxa Média'].iloc[0]\n",
    "                taxa_mercado = float(taxa_mercado) if taxa_mercado != '--' else np.nan\n",
    "                # Caso tenha um valor para duration e de taxa indicativa\n",
    "                if (durat_mercado != np.nan) and (taxa_mercado != np.nan):\n",
    "                    # Valores nulos por enquanto\n",
    "                    pre_ref_mercado_date = np.nan\n",
    "                    pre_ref_mercado_tax = np.nan\n",
    "                    spread_mercado_pre = np.nan\n",
    "                    # Interpolação entre os durations de ettj e seus taxas ettj pref e o duration usado\n",
    "                    ettj_ref_mercado_tax = np.interp(durat_mercado, np.array(ETTJ['Vertices']).astype(int), np.array(ETTJ['ETTJ PREF']).astype(float))\n",
    "                    # Cálculo do spread entre mercado e ettj\n",
    "                    spread_mercado_ettj = (1+taxa_mercado)/(1+ettj_ref_mercado_tax) - 1\n",
    "                # Preenchimento das colunas\n",
    "                aux = aux.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Dia': date, \n",
    "                    'Taxa Emissão': taxa_emi,\n",
    "                    'Volume Negociado': vol_neg, \n",
    "                    'PU Mercado': pu_mercado,\n",
    "                    'Duration Mercado': durat_mercado,\n",
    "                    'Taxa Mercado': taxa_mercado,\n",
    "                    'Pré Ref Mercado': pre_ref_mercado_date,\n",
    "                    'Taxa Pré Ref Mercado': pre_ref_mercado_tax,\n",
    "                    'Spread Pré Ref Mercado': spread_mercado_pre,\n",
    "                    'Taxa ETTJ Ref Mercado': ettj_ref_mercado_tax,\n",
    "                    'Spread ETTJ Ref Mercado': spread_mercado_ettj}, ignore_index=True)\n",
    "\n",
    "    df = df.append(aux, ignore_index=True) # Junta os dados novos com os antigos\n",
    "\n",
    "    clear_sheet(sheet) # Limpa a sheet com os dados antigos\n",
    "    pandas_to_excel(sheet, df) # Preenche a sheet com os dados antigos e novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import datetime\n",
    "from typing import Tuple\n",
    "\n",
    "global DATA_DEB\n",
    "global IMAB\n",
    "global REUNE\n",
    "global TAXAS_IPCA\n",
    "global TAXAS_CDI\n",
    "global TAXAS_PCT_CDI\n",
    "global ETTJ\n",
    "global RATING\n",
    "global INCENT\n",
    "global CONVEN\n",
    "global BDINFRA_path\n",
    "global date\n",
    "\n",
    "def clear_sheet(sheet: str) -> None:\n",
    "    \"\"\"\n",
    "        Função para limpar a sheet por completo\n",
    "\n",
    "        :param sheet: Nome da string para ser limpada no workbook\n",
    "    \"\"\"\n",
    "\n",
    "    global BDINFRA_path\n",
    "                                                                           \n",
    "    wb = openpyxl.load_workbook(BDINFRA_path)                                       \n",
    "    ws = wb[sheet]\n",
    "\n",
    "    for idx_row, row in enumerate(ws, 1): # Limpando cada célula da sheet\n",
    "        for col in row:\n",
    "            col.value = None\n",
    "    \n",
    "    wb.save(BDINFRA_path) #Salva as alterações\n",
    "\n",
    "def pandas_to_excel(sheet: str, df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "        Realizar a transição de pandas DataFrame para planilha em Excel\n",
    "\n",
    "        :param sheet: Nome da string para ser populada no workbook\n",
    "        :param df: DataFrame para ser usada para popular a sheet\n",
    "    \"\"\"\n",
    "    global BDINFRA_path\n",
    "\n",
    "    wb = openpyxl.load_workbook(BDINFRA_path)                                       \n",
    "    ws = wb[sheet]\n",
    "\n",
    "    rows = dataframe_to_rows(df, index=False) #Transforma o dataframe em várias células\n",
    "\n",
    "    for r_idx, row in enumerate(rows, 1): # Realiza o preenchimento da sheet\n",
    "        for c_idx, value in enumerate(row, 1):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "    wb.save(BDINFRA_path) #Salva as alterações\n",
    "\n",
    "def date_to_file(dt: str, type: str) -> str:\n",
    "    \"\"\"\n",
    "        Função para converter a data em nome dos files\n",
    "\n",
    "        :param dt: Data a ser analisada\n",
    "        :param type: Para qual documento será feito o ajuste\n",
    "    \"\"\"\n",
    "\n",
    "    dt = dt.split('/') # Retira os chars /\n",
    "\n",
    "    # Criação dos nome dos files de acordo com a data o tipo passado\n",
    "    if (type == 'IPCA') or (type == 'CDI') or (type == '%CDI'): \n",
    "        mes = {1: 'jan', 2: 'fev', 3: 'mar', 4: 'abr', 5: 'mai', 6: 'jun', 7: 'jul', 8: 'ago', 9: 'set', 10: 'out', 11: 'nov', 12: 'dez'}\n",
    "        file = 'd'+dt[2][-2:]+mes[int(dt[1])]+dt[0]+'.xls'\n",
    "\n",
    "    if type == 'REUNE':\n",
    "        file = 'REUNE_Acumulada_'+''.join(dt)+'.csv'\n",
    "\n",
    "    if type == 'IMAB':\n",
    "        file = 'IMA_'+''.join(dt)+'.csv'\n",
    "\n",
    "    if type == 'ETTJ':\n",
    "        file = 'CurvaZero_'+''.join(dt)+'.csv'\n",
    "    \n",
    "    return file # Retorna o nome do file\n",
    "\n",
    "def clean(df: pd.DataFrame , type: str) -> Tuple[pd.DataFrame, datetime.datetime]:\n",
    "    \"\"\"\n",
    "        Realizar pré-processamentos para bases a serem exploradas\n",
    "\n",
    "        :param df: DataFrame a ser realizado o pré-processamento\n",
    "        :param type: Para qual documento será feito o pré-processamento\n",
    "    \"\"\"\n",
    "\n",
    "    # Realiza o pré-processamento a depender do tipo\n",
    "    if (type == 'IPCA') or (type == 'CDI') or (type == '%CDI'):\n",
    "        col_1 = list(df.columns)[0]\n",
    "        idx_srt = list(df.index[df[col_1] == 'Código'])[0]\n",
    "        idx_end = list(df.index[df[col_1].astype(str).str.contains(\"[*]\")])[0]\n",
    "        columns = pd.Series(list(df.iloc[idx_srt]))\n",
    "        col_intind = list(columns[columns.astype(str).str.contains('Intervalo Indicativo')])\n",
    "        if len(col_intind) == 1:\n",
    "            columns = columns.fillna('Intervalo Indicativo Máxima')\n",
    "            columns = columns.replace(col_intind[0], \"Intervalo Indicativo Mínimo\")\n",
    "        df.columns = columns\n",
    "        df = df.iloc[idx_srt+2:idx_end]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['Nome'] = [name[:name.index('*')-2] if '*' in name else name for name in df['Nome']]\n",
    "        df['Nome'] = [name[:name.index('#')-2] if '#' in name else name for name in df['Nome']]\n",
    "\n",
    "    if type == 'REUNE':\n",
    "        df = df.reset_index()\n",
    "        col_1 = list(df.columns)[0]\n",
    "        idx_srt = list(df.index[df[col_1].astype(str).str.contains('CETIP')])[0]\n",
    "        columns = pd.Series(list(df.iloc[idx_srt]))\n",
    "        df.columns = columns\n",
    "        df = df.iloc[idx_srt+1:]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df[df['Agrupamento'] != 'SUBTOTAL']\n",
    "        df['Taxa Média'] = df['Taxa Média'].str.replace(',', '.')\n",
    "        df['Preço Médio'] = df['Preço Médio'].str.replace('.', '')\n",
    "        df['Preço Médio'] = df['Preço Médio'].str.replace(',', '.')\n",
    "\n",
    "    if type == 'IMAB':\n",
    "        df = df.reset_index()\n",
    "        col_1 = list(df.columns)[0]\n",
    "        idx_srt = list(df.index[df[col_1].astype(str).str.contains('Data')])[0]\n",
    "        columns = pd.Series(list(df.iloc[idx_srt]))\n",
    "        columns = [col[:col.index('*')] if '*' in col else col for col in columns]\n",
    "        df.columns = columns\n",
    "        df = df.iloc[idx_srt+1:]\n",
    "        df = df.reset_index(drop=True) \n",
    "        df['Duration (d.u.)'] = df['Duration (d.u.)'].str.replace('.', '')\n",
    "        df['Taxa Indicativa (% a.a.)'] = df['Taxa Indicativa (% a.a.)'].str.replace(',', '.')\n",
    "    \n",
    "    if type == 'ETTJ':\n",
    "        col_1 = list(df.columns)[0]\n",
    "        col_2 = list(df.columns)[1]\n",
    "        idx_srt = list(df.index[df[col_1] == 'Vertices'])[0]\n",
    "        idx_end = list(df.index[df[col_2].isnull()])[2]\n",
    "        df.columns = list(df.iloc[idx_srt])\n",
    "        df = df.iloc[idx_srt+1:idx_end]\n",
    "        df = df.drop(list(set(df.columns) - set(['Vertices', 'ETTJ IPCA', 'ETTJ PREF'])), axis = 1)\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['Vertices'] = df['Vertices'].str.replace('.', '')\n",
    "        df['ETTJ IPCA'] = df['ETTJ IPCA'].str.replace(',', '.')\n",
    "        df['ETTJ PREF'] = df['ETTJ PREF'].str.replace(',', '.')\n",
    "    \n",
    "    if type == 'DATA_DEB':\n",
    "        df['Codigo do Ativo'] = df['Codigo do Ativo'].str.replace(' ','')\n",
    "        df.columns = df.columns.str.replace(' ','')\n",
    "\n",
    "    dt_rat = None\n",
    "    if type == 'RATING':\n",
    "        dt_rat = pd.to_datetime(df.columns[0])\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df.iloc[1:]\n",
    "\n",
    "    return df, dt_rat # Retorna o DataFrame já ajustado para análises\n",
    "\n",
    "def source(dt: str):\n",
    "    \"\"\"\n",
    "        Pegar base de dados crua\n",
    "\n",
    "        :param str: Data para ser analisada\n",
    "    \"\"\"\n",
    "    \n",
    "    downloads_path = \"~\\Downloads\"\n",
    "    downloads_path = os.path.expanduser(downloads_path)\n",
    "\n",
    "    global date\n",
    "    date = dt\n",
    "\n",
    "    global DATA_DEB\n",
    "    DATA_DEB = pd.read_table(os.path.join(downloads_path, \"Debentures.com.br_Caracteristica_em_03-03-2021_as_21-19-42.xls\"), encoding='ANSI')\n",
    "    DATA_DEB, Lixo  = clean(DATA_DEB, 'DATA_DEB')\n",
    "\n",
    "    global IMAB\n",
    "    IMAB = pd.read_csv(os.path.join(downloads_path, date_to_file(date, 'IMAB')), sep=\";\", encoding='ANSI')\n",
    "    IMAB, Lixo  = clean(IMAB, 'IMAB')\n",
    "\n",
    "    global REUNE\n",
    "    REUNE = pd.read_csv(os.path.join(downloads_path, date_to_file(date, 'REUNE')),sep=\";\",header=2, encoding='ANSI')\n",
    "    REUNE, Lixo = clean(REUNE, 'REUNE')\n",
    "\n",
    "    global TAXAS_IPCA\n",
    "    TAXAS_IPCA = pd.read_excel(os.path.join(downloads_path, date_to_file(date, 'IPCA')), sheet_name='IPCA_SPREAD')\n",
    "    TAXAS_IPCA, Lixo = clean(TAXAS_IPCA, 'IPCA')\n",
    "\n",
    "    global TAXAS_CDI\n",
    "    TAXAS_CDI = pd.read_excel(os.path.join(downloads_path, date_to_file(date, 'CDI')), sheet_name='DI_SPREAD')\n",
    "    TAXAS_CDI, Lixo = clean(TAXAS_CDI, 'CDI')\n",
    "\n",
    "    global TAXAS_PCT_CDI\n",
    "    TAXAS_PCT_CDI = pd.read_excel(os.path.join(downloads_path, date_to_file(date, '%CDI')), sheet_name='DI_PERCENTUAL')\n",
    "    TAXAS_PCT_CDI, Lixo = clean(TAXAS_PCT_CDI, '%CDI')\n",
    "\n",
    "    global ETTJ\n",
    "    ETTJ = pd.read_csv(os.path.join(downloads_path, date_to_file(date, 'ETTJ')),sep=\";\", encoding='ANSI')\n",
    "    ETTJ, Lixo = clean(ETTJ, 'ETTJ')\n",
    "\n",
    "    global Z\n",
    "    Z = pd.read_excel(os.path.join(downloads_path, \"Rating.xlsx\"))\n",
    "    Z, dt_rate = clean(Z, 'RATING')\n",
    "\n",
    "    global INCENT\n",
    "    INCENT = pd.read_excel(os.path.join(downloads_path, \"003. Debêntures Incentivadas v01.xlsx\"), skiprows=2)\n",
    "\n",
    "    global CONVEN\n",
    "    CONVEN = pd.read_excel(os.path.join(downloads_path, \"004. Debêntures Convencionais v01.xlsx\"))\n",
    "\n",
    "    global BDINFRA_path \n",
    "    BDINFRA_path = os.path.join(downloads_path, \"BD Infra - Secundário - Copia.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "source('26/02/2021')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0   Emissor Rating Agência Rating Equivalente\n",
       "425  VSJH11      A   Fitch                  A"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emissor</th>\n      <th>Rating</th>\n      <th>Agência</th>\n      <th>Rating Equivalente</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>425</th>\n      <td>VSJH11</td>\n      <td>A</td>\n      <td>Fitch</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "Z[Z['Emissor'] == 'VSJH11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}